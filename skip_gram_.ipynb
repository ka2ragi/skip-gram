{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#概要\n",
        "##Penn TreeBankデータセットを用いて単語の分散表現を獲得することを目指します。一般に、単語の分散表現を得るには、word2vecと呼ばれる手法を用います。word2vecには、CBOWモデルとskip-gramモデルの二つが提案されていますが、ここではskip-gramモデルを実装していきます。"
      ],
      "metadata": {
        "id": "sHZHUN1BvShx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##設定"
      ],
      "metadata": {
        "id": "DhnZmFYxVbYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "6L1s0iJKkcdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b19e59-ba73-4d2e-b633-249f40ae25de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/drive/MyDrive/path/to/your/dir'"
      ],
      "metadata": {
        "id": "-phAbeDzmHqo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 再現性の確保\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# シード値\n",
        "seed = 42\n",
        "\n",
        "# CPUおよびGPUの乱数生成器のシードを固定\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # マルチGPUを使用する場合\n",
        "\n",
        "# CuDNNの挙動を決定論的に\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# NumPyの乱数生成器のシードを固定\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Pythonの組み込み乱数生成器のシードを固定\n",
        "random.seed(seed)\n"
      ],
      "metadata": {
        "id": "-xfo6aY6W3uZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PTBデータセットのダウンロード\n",
        "###PTBデータセットをダウンロードします。Google Colabのディスクに保存すると、セッションが切れるごとに再ダウンロードが必要になります。\n"
      ],
      "metadata": {
        "id": "z5kQbuGPVssN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "url_base = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/'\n",
        "files = ['ptb.train.txt', 'ptb.valid.txt', 'ptb.test.txt']\n",
        "\n",
        "for file in files:\n",
        "\n",
        "  save_path = root_path + \"/\" + file\n",
        "  if os.path.exists(save_path):\n",
        "    print(f\"{file} already exists.\")\n",
        "    continue\n",
        "\n",
        "  url = url_base + file\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    with open(save_path, \"wb\") as f:\n",
        "      f.write(response.content)\n",
        "\n",
        "      print(f\"{file} downloaded and saved successfully.\")\n",
        "\n",
        "  else:\n",
        "    print(f\"{file} failed to download. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "id": "LRGSKjdkmNTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7251c69e-0758-4393-97fc-96c327906612"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptb.train.txt downloaded and saved successfully.\n",
            "ptb.valid.txt downloaded and saved successfully.\n",
            "ptb.test.txt downloaded and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##コーパスの作成\n",
        "###ここではコーパスおよび語彙とIDの辞書を作成する以下の関数を実装します。\n",
        "- load_corpus：PTBデータセットを用いてcorpus, word_to_id, id_to_wordを作成します。\n",
        "\n"
      ],
      "metadata": {
        "id": "K9WQ5ykUV7CN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = ['ptb.train.txt']"
      ],
      "metadata": {
        "id": "vypOA61Zjbb_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "def load_corpus(files: List[str], root_path: str) -> Tuple[np.ndarray, Dict[str, int], Dict[int, str]]:\n",
        "    word_to_id: Dict[str, int] = {}\n",
        "    id_to_word: Dict[int, str] = {}\n",
        "\n",
        "    for file in files:\n",
        "        with open(root_path + '/' + file, \"r\") as ff:\n",
        "            words = ff.read().replace(\"\\n\", \"<eos>\").strip().split()\n",
        "\n",
        "            for word in words:\n",
        "                if word not in word_to_id:\n",
        "                    tmp_id = len(word_to_id)\n",
        "                    word_to_id[word] = tmp_id\n",
        "                    id_to_word[tmp_id] = word\n",
        "\n",
        "    corpus: np.ndarray = np.array([word_to_id[w] for w in words])\n",
        "\n",
        "    return corpus, word_to_id, id_to_word\n",
        "\n"
      ],
      "metadata": {
        "id": "RrXiyDostq0P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Negative Sampling\n",
        "###ここではNegative Samplingのためのクラスを実装しますが、この際にデータ型に注意してください。また、実装するうえで以下のレポジトリを参考にしました。\n",
        "https://github.com/oreilly-japan/deep-learning-from-scratch-2/blob/master/ch04/negative_sampling_layer.py"
      ],
      "metadata": {
        "id": "d61VmWTbYgVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "class UnigramSampler:\n",
        "    def __init__(self, corpus, power, sample_size):\n",
        "        self.sample_size = sample_size\n",
        "        self.vocab_size = None\n",
        "        self.word_p = None\n",
        "\n",
        "        # 'corpus' はnumpy配列として扱われます\n",
        "        counts = Counter(corpus)\n",
        "        vocab_size = len(counts)\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.word_p = np.zeros(vocab_size)\n",
        "        for i in range(vocab_size):\n",
        "            self.word_p[i] = counts[i]\n",
        "\n",
        "        self.word_p = np.power(self.word_p, power)\n",
        "        self.word_p /= np.sum(self.word_p)\n",
        "\n",
        "    def get_negative_sample(self, target):\n",
        "        # 'target' はtorch.Tensorとして扱われます\n",
        "        if target.dim() == 0:\n",
        "          target = target.unsqueeze(0)\n",
        "        batch_size = target.size(0)\n",
        "        negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            p = self.word_p.copy()\n",
        "            target_idx = target[i].item()  # targetからnumpy indexを取得\n",
        "            p[target_idx] = 0\n",
        "            p /= p.sum()\n",
        "\n",
        "            negative_sample[i, :] = np.random.choice(self.vocab_size, self.sample_size, replace=False, p=p)\n",
        "\n",
        "        # 'negative_sample' はtorch.Tensorとして返されます\n",
        "        return torch.from_numpy(negative_sample).long()\n"
      ],
      "metadata": {
        "id": "OMv9WCQeLKdE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##データの準備\n",
        "###ここではPyTorchのDataset、DataLoaderクラスを用いて学習に必要なデータセットを作成します。ここでもデータ型に注意して実装してください。\n",
        "- CustomDatasetクラス：学習に使えるようにデータを成形します。\n",
        "- DataLoader：学習時のバッチ処理を効率的に行います。\n"
      ],
      "metadata": {
        "id": "AtdEMdHTZVRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "KzZeQMOrareE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus, word_to_id, id_to_word = load_corpus(files, root_path)"
      ],
      "metadata": {
        "id": "PIn_gNYnaQtD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データ準備_1\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, corpus, window_size=5):\n",
        "    self.corpus = corpus\n",
        "    self.window_size = window_size\n",
        "    self.target = torch.from_numpy(corpus[window_size:-window_size]).long()\n",
        "    self.contexts = self._create_contexts(corpus, window_size)\n",
        "    self.sampler = UnigramSampler(corpus, power=0.75, sample_size=5)\n",
        "\n",
        "  def _create_contexts(self, corpus, window_size):\n",
        "    contexts = []\n",
        "    for idx in range(window_size, len(corpus)-window_size):\n",
        "        cs = []\n",
        "        for t in range(-window_size, window_size + 1):\n",
        "            if t == 0:\n",
        "                continue\n",
        "            cs.append(corpus[idx + t])\n",
        "        contexts.append(cs)\n",
        "\n",
        "    contexts = torch.stack([torch.tensor(c) for c in contexts])\n",
        "\n",
        "    return contexts\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.target)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_inputs = self.target[idx]\n",
        "    batch_positive = self.contexts[idx]\n",
        "    batch_negative = self.sampler.get_negative_sample(batch_inputs)\n",
        "    batch_negative = batch_negative.squeeze(0)\n",
        "\n",
        "    return batch_inputs, batch_positive, batch_negative\n"
      ],
      "metadata": {
        "id": "m6TVRvHJnoXs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# データ準備2\n",
        "corpus, word_to_id, id_to_word = load_corpus(files, root_path)\n",
        "vocab_list = list(word_to_id.keys())\n",
        "ptb_dataset = CustomDataset(corpus, window_size=5)\n",
        "ptb_dataloader = DataLoader(ptb_dataset, batch_size=100, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "ttFP6kwbrwZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89ab21b-fa0c-4a80-8576-b7e9157a6b71"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16 s, sys: 1.22 s, total: 17.2 s\n",
            "Wall time: 16.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 動作確認\n",
        "for batch_target, batch_positive, batch_negative in ptb_dataloader:\n",
        "    print(\"Target:\", batch_target)\n",
        "    print(\"Positive:\", batch_positive)\n",
        "    print(\"Negative Sample:\", batch_negative)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZmh2plluKxu",
        "outputId": "d6b3f3b2-18fa-47d9-9048-c751deb01da3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: tensor([  27,   54,   95,  321,  459,   32, 6725,  393,  351, 1153, 7172, 3552,\n",
            "        1781,   34,   26, 4584,   64, 4734,   26,   69,   69, 3480, 4919, 2096,\n",
            "          78,  229, 4444,  432,   26, 9444,  119, 1845,   26,   26, 1624,  753,\n",
            "         315,  307,   32, 1602,   64,   54,   30,  113,   98,  307,   24,   64,\n",
            "         181, 2993, 7035, 1753,   99, 6324,  159,   24,  396,  154,  923, 8084,\n",
            "          54,   27,   26,   64,  424,  936,   27,  160,  719,  790,   26,  623,\n",
            "         160,   34,  154,   48,  468,   26,   42, 3394, 5424, 1106, 1035, 2304,\n",
            "          40,  169,  674,  933,  237,   32, 2464, 9779, 2380,  229, 6527,  130,\n",
            "        3091,  187,  418, 1045])\n",
            "Positive: tensor([[ 160,  416,   27,   95,  416,   24, 1140,  334, 3885,   30],\n",
            "        [2887,   64,   26,   24,   78, 5147,   24,   78,   54,   26],\n",
            "        [  48,  987, 6955,  154, 1070,   26, 3938,   24,   78,  119],\n",
            "        [3027, 4585,   24,  914, 6673,  176, 1982,   26,  152, 1730],\n",
            "        [ 952, 8429,   32, 6123,  360,  902,   24,   39, 8429,   98],\n",
            "        [  40, 1493,   64, 4052,  152, 9816, 6040,   24,  531,   32],\n",
            "        [  32,  935,  938,  551,  160,  437,   98,   93,  424,  678],\n",
            "        [  39,   26,  623,  251,  220,  181, 1218,  932,   24, 1199],\n",
            "        [ 593, 6027, 3532,  108,   32,  352, 3316,   27,  444,   64],\n",
            "        [ 924,  108,  925,   78,   30,  409, 1053, 5820,   93,  119],\n",
            "        [ 103,  416,   27,  468,   42, 1604,  437, 1162,  744,  108],\n",
            "        [  32, 2715,   48,  570,  813, 1128,  108,  504,   24, 4823],\n",
            "        [ 220, 4067,  693,   48,   64,   38,   27,   27,   24,  416],\n",
            "        [ 997,   42,  507,   54, 8000,   35,  381,   93,  101,  934],\n",
            "        [2866,   48,   82,  674,   24, 2884, 1231,   48,   26,  159],\n",
            "        [1040, 1153,  251,  154,  138,   87,  213,  148, 1234,   64],\n",
            "        [  27, 9347, 3656,   54,  133,  530,  152,   35,  416,   27],\n",
            "        [ 861,   26,  956, 4343,  861,  451,  491,   48, 1237,   26],\n",
            "        [5392, 1040, 2993, 2797,   48,  108,  318,  302,   24,  128],\n",
            "        [ 496,   26,   26,   26,   93,  552,   63,  181, 8670,  229],\n",
            "        [1106,   24,   32, 1717,  204, 1718,  169, 1719,   64,   26],\n",
            "        [  35,  466,   24,   32, 2750, 4213, 5762,  144,   48,   26],\n",
            "        [  87,  109,  462,   42,   35,   42,   26, 1486, 1629,   24],\n",
            "        [  32,  928, 7828,   34,  374, 1153,   98, 5676, 1714,   26],\n",
            "        [ 910,   32,   79,   26,  595,   40, 1987,   64,   32, 1524],\n",
            "        [  48,   32,   26, 2854, 1122, 2622, 2142,  169,  416,   27],\n",
            "        [  42,   93, 5057,   32, 7223,   30,  220, 1041,  119,   26],\n",
            "        [  93,   27,   27,   42, 7193, 8145,  777, 1960,  315,   32],\n",
            "        [3901,   32, 4721, 5264,   26,  119, 1319,  460,  315, 1140],\n",
            "        [  24,  108,   32, 3921,  378,   83, 2772, 2523,   42,  416],\n",
            "        [  42,   78,   24,   32,  574, 2493, 1564,   33,   69, 2569],\n",
            "        [  24,  303, 2071,   69, 2623,  365,  109, 3682,  108, 1054],\n",
            "        [6266,  226, 4363,   32, 8202, 4348,   26,   48,   26,   26],\n",
            "        [ 841, 4059,   54,  615,  108,   32, 1100,   35, 4366,   42],\n",
            "        [  26, 4577,  108,  227,   32, 2479,  133, 1093,  459, 1780],\n",
            "        [1482, 1709, 7445,   64,   32,  133,  872, 5698,  108, 7358],\n",
            "        [  76, 1153,   32, 7515,   24,  566, 1727,   24,   39,   26],\n",
            "        [  35, 1619, 4020, 2003,   24, 1167, 2005,   64,  323,   40],\n",
            "        [  98,   78,  432,  251, 2797, 3423,   48,  623,  251, 1218],\n",
            "        [ 169,   32, 3661, 2732, 6055,  652, 1193,   81,   24,  315],\n",
            "        [  24, 1072, 1419,  103, 1661, 1771,  109, 7725, 1087,  558],\n",
            "        [5204,   24,   39, 5782,  840,   55,   35,   37,  749,   32],\n",
            "        [ 152, 9655, 1401,   48, 3781, 5638, 3034,   64, 1088, 4297],\n",
            "        [ 328,   34,   42,  267,   27, 1032,  160,   79,   80, 8601],\n",
            "        [  26,   24, 2222, 1339, 1624,  109,   33,  461,   32, 6406],\n",
            "        [9724, 1950,  289,   32,  574,   42,  227, 4391,  931,   24],\n",
            "        [5608,  872, 2247,   48,   26,  244,   26, 1922,  113, 3797],\n",
            "        [  26, 3569,   48, 1408, 3155, 1420, 4207,   24,   35, 9448],\n",
            "        [1932, 1123,   42,   32, 2970,   32,  841, 5126, 1515,   42],\n",
            "        [  32, 2913,  685, 3955,  130,  432,  365,   32,  431,   26],\n",
            "        [6739,   64,   32,  189,  119, 2761,   24,   32, 2014,   78],\n",
            "        [7643,   42,   32, 1766, 5221, 2129, 1665, 2804,   27, 1996],\n",
            "        [1760,   87, 5850, 5851, 5852,   98, 1414,  840,   69, 2947],\n",
            "        [  42, 1195, 1634,   64,  682,  965,  966,   48,  108,  307],\n",
            "        [  48,  888, 1812,  532,  318,  652,   26,   93, 2289,  251],\n",
            "        [1624,   42, 1041,  108,  396,   32, 2230, 1624,  840, 7134],\n",
            "        [ 932,   24,  110,  245, 8380, 5711,   78,  119,  646,  566],\n",
            "        [ 854,   24,  365,  248, 8640,  734,  795,  997,   42, 3286],\n",
            "        [ 930,  331, 3665,  133,   35, 3259, 2227,  169, 1146, 4987],\n",
            "        [5134, 2613,   35, 2266,   42, 6740,   24,  133,   35, 1028],\n",
            "        [  40,  145,   24,  758, 1519,  108,  913,   87, 7241,  301],\n",
            "        [ 109,   27,   26,  181,  416,   24,  169, 1331,  141,   40],\n",
            "        [ 416,   27,  187,  853, 7286,  395,   42, 3919,  733,   24],\n",
            "        [ 127,  181,  504,   30,  220, 4470,  795, 1253,   40,  825],\n",
            "        [ 338,   64,  792,   35, 4496, 3006,  668,   95,  181,   35],\n",
            "        [ 152,   32,  101,  934,  935,  152, 1362,   93, 3647, 3648],\n",
            "        [ 108, 1969,   64,   32,   27, 5123, 4299, 3213,  229, 5473],\n",
            "        [  32,  458, 2808,   54, 1032,   27,  187,  930,   95,  169],\n",
            "        [1563,   48, 5824,  234,  718,  762,  531, 7388,  113, 3915],\n",
            "        [1521,   24,  108,   32,  663, 7080, 6766, 4137,  416,   27],\n",
            "        [  64,  474,  229,  974,   26,   42,  237,  845,  929,   24],\n",
            "        [3985,  382,  171,  774, 2165, 1940,  307,   42,  214,  148],\n",
            "        [ 159,  382,   24,   48,  605, 2634,  108,  256, 1420, 1780],\n",
            "        [4790,  130,  238,  885,   78,   35,   26,   24, 7032,  119],\n",
            "        [4956, 9838,  119,  245, 6086, 3356,   71, 1569,  896,   24],\n",
            "        [  40,   93,  307, 1502, 3817,  734,  182, 7769,   98, 7037],\n",
            "        [5798, 5799,  270,  416,   27,   42, 1066, 5800,  503,   27],\n",
            "        [  39,   26,   30, 2228,   32,   48, 6724, 1088,   42,   26],\n",
            "        [  26, 3222,  301,  987, 5289, 7969, 6648,   48,  320,   35],\n",
            "        [ 204,  734,  745,   64, 3208, 3395,  229, 7356,  289, 1339],\n",
            "        [8219, 1757, 4331, 2821,   48,  181, 6255, 1769,   24,  130],\n",
            "        [  78, 3356,   32, 1623,  943,   42, 1945, 1946,  230, 1947],\n",
            "        [  39, 3933,   26,   32,   26, 2507, 5244,   26,   26,   24],\n",
            "        [9706,  119, 4393,  935,  924, 1652,   24,   32, 8768, 2312],\n",
            "        [ 431,   24,  373,   32, 4979,  646,   26,   64, 1153,   93],\n",
            "        [3795,   24,  225, 3431, 3430,   32,  189,  119,   27,  944],\n",
            "        [ 396,  220, 7324,   24, 8191,   32, 3241,  209, 2379,  159],\n",
            "        [ 416,   27,  468,  467,   27,   35,  466,  152,  497,   42],\n",
            "        [  26, 9729, 7392,  108,   32,   34,   35, 5490, 2001,  232],\n",
            "        [  34, 1420, 2584,   26,  895, 1485, 5907,   42,   26,   48],\n",
            "        [  64, 5508,  119, 1623, 1961, 4622,   32, 3899, 4633,  757],\n",
            "        [ 373,   42, 1352,  229,   39,   35,  459, 2079,   64, 1573],\n",
            "        [2980, 3203,   39, 8817, 8818,   93,   26, 3050, 4028,  130],\n",
            "        [ 245, 3902, 3903,  489,  969,   35, 1773, 5596,  181,   32],\n",
            "        [ 435, 3233,   32,  189,  119,  160, 3807,   26,   24,   78],\n",
            "        [5088, 1975,   24,  895,  373, 2993,  883,  307,   26,  653],\n",
            "        [3440,   24,   32,   26,  113,   93,  374, 3001,  594,   95],\n",
            "        [ 357, 1561,   42,  416,   27, 5027,  133,   27,   27,   42],\n",
            "        [6874, 4299,   40, 1428, 2500,  159,  188,  108, 3583, 6858],\n",
            "        [1000,   27,   64,  935,   42,   38,   27,   24,  603,  170]])\n",
            "Negative Sample: tensor([[  78, 2485,   54, 5079, 8569],\n",
            "        [7886, 6784, 4857, 2124,  935],\n",
            "        [1988,  220, 5376, 1194,  315],\n",
            "        [2254,  466,  582, 1100,   26],\n",
            "        [2680, 4918, 1880, 4580, 2890],\n",
            "        [ 108, 3486,  908, 9943, 4125],\n",
            "        [5962,   35, 3257,  109, 1339],\n",
            "        [ 351, 6864,  804, 1729, 3932],\n",
            "        [3777, 9572,  130, 3989, 1799],\n",
            "        [ 778,  383,  623,  115, 7334],\n",
            "        [5132,  674, 4414, 3252,   88],\n",
            "        [ 187, 8673,  275, 1632,  826],\n",
            "        [1512, 2304, 5939, 1088,   69],\n",
            "        [  32,  602,   26,   24, 1153],\n",
            "        [  48,  848, 1715, 1066, 6151],\n",
            "        [ 159,  108,  413, 5129, 5179],\n",
            "        [2303, 2977, 2116, 7459,   34],\n",
            "        [1029,   93, 6321, 8690,  408],\n",
            "        [ 917, 7166, 8192,  243,  874],\n",
            "        [2707,  853, 1562, 2303, 1321],\n",
            "        [ 685,  815,   24,  526, 9323],\n",
            "        [  32, 2158, 1190,  408, 1253],\n",
            "        [ 113,  882, 2842, 1636,  820],\n",
            "        [5396, 1034,  108, 5057, 2688],\n",
            "        [ 689, 1401, 7917, 9178, 4997],\n",
            "        [4222,  594, 2803, 5763,   42],\n",
            "        [  64, 4482, 1861,   27, 2856],\n",
            "        [1304, 7481,  555, 7802,  154],\n",
            "        [ 229,   65,  358, 1175,  476],\n",
            "        [2230,  280, 6108, 2430,   26],\n",
            "        [ 433,  466,   56,  383,   32],\n",
            "        [ 489, 7928, 3101, 9797, 2303],\n",
            "        [ 590, 2476,  895, 6364, 1294],\n",
            "        [ 817,  738,   48,  152, 1314],\n",
            "        [7635, 5362,  757, 2873,   64],\n",
            "        [1786, 1260, 5340,   42, 2525],\n",
            "        [  48,   26, 4102, 2399, 1128],\n",
            "        [ 887, 5072,   98, 2376, 2679],\n",
            "        [9009, 4670,  392,  616,  710],\n",
            "        [8763,   42, 2382, 1742,  167],\n",
            "        [ 875,  119, 1487, 5639,  499],\n",
            "        [ 337, 1935,   95, 7083, 6962],\n",
            "        [1260, 2896, 2496,   32, 3351],\n",
            "        [1262,  888,   40,  694,   28],\n",
            "        [7632,  639, 4243,   40, 1483],\n",
            "        [1791, 1821,  775,  495, 1922],\n",
            "        [1004, 6790,  227, 7500, 3466],\n",
            "        [1028, 1319, 1325,  628,  225],\n",
            "        [  35,  495,   32, 5746,  119],\n",
            "        [ 801, 3185, 4364, 1486,  695],\n",
            "        [5335, 1961, 4090, 2111,   26],\n",
            "        [ 637,  124, 5298, 7958, 3730],\n",
            "        [1928, 4856,  351,   27, 9694],\n",
            "        [ 196, 3205, 7548, 5620,  249],\n",
            "        [ 886, 2598,  160, 1584, 3901],\n",
            "        [8369, 4794, 3513, 2095,  284],\n",
            "        [ 142, 3990,  468, 2093, 9413],\n",
            "        [2906, 3155, 3628,   42, 7368],\n",
            "        [  93, 3116, 1293,  433, 3638],\n",
            "        [  93,  114, 1338,   24,  352],\n",
            "        [8911, 1725,  129, 3965,   27],\n",
            "        [8930,  247,  840, 5886, 1485],\n",
            "        [6475, 6775,  315, 3423, 2287],\n",
            "        [1374, 6773, 3605, 6437, 6003],\n",
            "        [3349, 2577,  363,  119, 3142],\n",
            "        [1359, 2531,   32,  312,  661],\n",
            "        [7072, 2129, 9939, 8844,   64],\n",
            "        [1026, 1420,  554,   87, 6566],\n",
            "        [ 321,  162,  233, 5793,  733],\n",
            "        [ 337, 3647, 1800,  647, 1487],\n",
            "        [4521, 3408,  801,  339,  591],\n",
            "        [4495,  555, 1903,   32,  416],\n",
            "        [  56, 9484,  931,  251,  108],\n",
            "        [3774, 4310, 1761,   42, 3144],\n",
            "        [7790, 6095,  169,  172,  745],\n",
            "        [4168,  119, 9984,   24, 3313],\n",
            "        [ 823,  498, 1088, 1600,   27],\n",
            "        [ 203, 1195, 2942, 4955, 3614],\n",
            "        [1845, 3315,  128, 7918, 3558],\n",
            "        [  87,  350,   39, 3847,  554],\n",
            "        [1556,   35, 2897,  284, 7083],\n",
            "        [1072, 3876, 2169, 4052, 1020],\n",
            "        [1832,  222, 3823,   54, 1639],\n",
            "        [2215, 7298,   42, 2901, 3017],\n",
            "        [1094, 1027, 4982,  277, 1260],\n",
            "        [  30, 1523,   32,   42,  882],\n",
            "        [7383,  864, 4479,   26,  114],\n",
            "        [ 425,  337, 1006, 5794,  101],\n",
            "        [ 247,  718, 9279,   27, 1164],\n",
            "        [ 818,   56, 3023,  168,  235],\n",
            "        [2130, 5431,  290, 1577,   24],\n",
            "        [4074,  718, 1419,   93, 1569],\n",
            "        [7318, 1009,  920,   54,   48],\n",
            "        [4078,  181,  652,  131,  468],\n",
            "        [5607, 6800, 3094, 1513, 9036],\n",
            "        [5054,   32, 5080, 1954,  245],\n",
            "        [5448, 6417,  895,   64, 3192],\n",
            "        [4930, 6465, 4617,  229, 8123],\n",
            "        [ 801,  204,  639,   24,   51],\n",
            "        [  35, 7001, 5859, 3143, 2843]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ニューラルネットワークの設計\n",
        "###ここではskip-gramモデルを実装します。次元に注意してください。"
      ],
      "metadata": {
        "id": "QjMjSOpVZvpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_size):\n",
        "    V, H = vocab_size, hidden_size\n",
        "\n",
        "    super().__init__()\n",
        "    self.embeds_i = nn.Embedding(V, H)\n",
        "    self.embeds_o = nn.Embedding(V, H)\n",
        "\n",
        "  def forward(self, inputs, pos_samples, neg_samples):\n",
        "    embeds_i = self.embeds_i(inputs)\n",
        "\n",
        "    num_context_words = pos_samples.shape[1]   # 2 * window_size = 10\n",
        "    num_negative_words = neg_samples.shape[1]  # sample_size = 5\n",
        "    pos_samples = pos_samples.view(-1)\n",
        "    neg_samples = neg_samples.view(-1)\n",
        "\n",
        "    embeds_p = self.embeds_o(pos_samples).view(-1, num_context_words, self.embeds_o.embedding_dim)\n",
        "    embeds_n = self.embeds_o(neg_samples).view(-1, num_negative_words, self.embeds_o.embedding_dim)\n",
        "\n",
        "    # POS\n",
        "    pos_score = torch.sum(embeds_i.unsqueeze(1) * embeds_p, dim=2)\n",
        "\n",
        "    # NEG\n",
        "    neg_score = torch.sum(embeds_i.unsqueeze(1) * embeds_n, dim=2)\n",
        "\n",
        "    return pos_score.sigmoid(), neg_score.sigmoid()\n"
      ],
      "metadata": {
        "id": "3JlTIAuPbLVq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##学習\n",
        "###実際にデータを使って学習します。ここではtrainer関数を実装します"
      ],
      "metadata": {
        "id": "PRZHmYC8uy0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def trainer(net, max_epochs=10, LR=0.002, verbose=True):\n",
        "  # DataLoaderの設定\n",
        "  dl_dict = {'train': ptb_dataloader}\n",
        "\n",
        "  # 初期化関数の定義\n",
        "  def weight_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Embedding') != -1:\n",
        "      with torch.no_grad():\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "\n",
        "  # デバイスの確認\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  compute_device = \"GPU\" if device.type == \"cuda\" else \"CPU\"\n",
        "  print(f\"This is {compute_device} trainer !!\")\n",
        "  print(\"-\"*20, 'Start', \"-\"*20)\n",
        "\n",
        "  net.to(device)\n",
        "\n",
        "  # 初期化\n",
        "  net.apply(weight_init)\n",
        "\n",
        "  # 訓練モード\n",
        "  net.train()\n",
        "  torch.backends.cudnn.benchmark = False   # Trueにすると学習が高速になる(かもしれない)が再現性がなくなる\n",
        "\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
        "  losses = torch.zeros(max_epochs)\n",
        "  accuracies = torch.zeros(max_epochs)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    phase = 'train'\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_pred = 0\n",
        "    total_pred = 0\n",
        "    for batch_target, batch_positive, batch_negative in tqdm(dl_dict[phase]):\n",
        "      inputs = batch_target.to(device)\n",
        "      pos_samples = batch_positive.to(device)\n",
        "      neg_samples = batch_negative.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      with torch.set_grad_enabled(phase=='train'):\n",
        "        pos_s, neg_s = net(inputs, pos_samples, neg_samples)\n",
        "        loss = -torch.log(pos_s + 1e-10).sum() - torch.log(1 - neg_s + 1e-10).sum()\n",
        "\n",
        "        # 正解数をカウント\n",
        "        # pos_s >= 0.5で正とみなす\n",
        "        predictions = pos_s >= 0.5                 # True/Falseを保存\n",
        "        correct_pred += predictions.sum().item()   # Trueの合計(各エポックでの正解数)\n",
        "        total_pred += predictions.numel()          # predictionsの要素数(Falseを含む)\n",
        "\n",
        "        if phase == 'train':\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "\n",
        "    losses[epoch] = running_loss / len(dl_dict[phase].dataset)\n",
        "    accuracies[epoch] = correct_pred / total_pred\n",
        "\n",
        "    if verbose:\n",
        "      print('Epoch {}/{} | {:^5} | Loss: {:.4f} | Accuracy: {:.4f}'.format(\n",
        "          epoch+1,\n",
        "          max_epochs,\n",
        "          phase,\n",
        "          losses[epoch],\n",
        "          accuracies[epoch])\n",
        "      )\n",
        "\n",
        "  writer.close()\n",
        "  return net, losses, accuracies\n",
        "\n"
      ],
      "metadata": {
        "id": "ugga9U1heZXq"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = SkipGram(vocab_size=len(word_to_id), hidden_size=100)"
      ],
      "metadata": {
        "id": "JKnB-R9ylo9I"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trained_net, losses, accuracies = trainer(net, max_epochs=10, LR=0.001, verbose=True)"
      ],
      "metadata": {
        "id": "cqw3Ki7xkxqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9806514a-26aa-4383-9350-a33e02155157"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is GPU trainer !!\n",
            "-------------------- Start --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:24<00:00, 28.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | train | Loss: 8.6780 | Accuracy: 0.8878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:20<00:00, 28.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 | train | Loss: 8.3633 | Accuracy: 0.8888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:14<00:00, 29.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 | train | Loss: 8.2126 | Accuracy: 0.8905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:13<00:00, 29.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 | train | Loss: 8.1117 | Accuracy: 0.8926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:15<00:00, 29.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 | train | Loss: 8.0228 | Accuracy: 0.8947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:18<00:00, 29.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 | train | Loss: 7.9488 | Accuracy: 0.8966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:19<00:00, 29.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 | train | Loss: 7.8898 | Accuracy: 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:16<00:00, 29.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 | train | Loss: 7.8341 | Accuracy: 0.9007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [06:03<00:00, 25.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 | train | Loss: 7.7892 | Accuracy: 0.9021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9296/9296 [05:32<00:00, 27.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 | train | Loss: 7.7495 | Accuracy: 0.9035\n",
            "CPU times: user 52min 26s, sys: 27.6 s, total: 52min 53s\n",
            "Wall time: 54min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 重みの保存\n",
        "import os\n",
        "save_path = root_path + \"/weights/\"\n",
        "if not os.path.exists(save_path):\n",
        "  os.makedirs(save_path)\n",
        "\n",
        "torch.save(trained_net.state_dict(), save_path + \"model_weights.pth\")"
      ],
      "metadata": {
        "id": "vfRm2ObNxzlR"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "E3JUaUGdYAbw",
        "outputId": "dda27680-abb9-4fb8-90fa-ec54c39ee43f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## skip-gramモデルの評価\n",
        "###ここでは学習によって得られた単語ベクトルを用いて、今回のモデルの性能を評価します。次の二つの方法で評価していきます。\n",
        "- ベクトルの類似度：単語ベクトル同士の類似度を計算して私たちの感覚と合致するか確認します\n",
        "- 類推問題：king：man = queen：? のような問題が解けるのかを確認します"
      ],
      "metadata": {
        "id": "2Qkf-Xa8xvBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語ベクトル\n",
        "weights = trained_net.state_dict()\n",
        "in_embeds_weights = weights['embeds_i.weight']\n",
        "print(in_embeds_weights.shape)"
      ],
      "metadata": {
        "id": "t1R4OQGU2QOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価関数の定義\n",
        "# 以下のレポジトリを参考にしました\n",
        "# https://github.com/oreilly-japan/deep-learning-from-scratch-2/blob/master/common/util.py\n",
        "import numpy\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def cos_sim(x, y):\n",
        "  return F.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0)).item()\n",
        "\n",
        "def most_sim(query, word_to_id, id_to_word, word_matrix, top=5):\n",
        "  if query not in word_to_id:\n",
        "    print(f'{query} is not found.')\n",
        "    return\n",
        "\n",
        "  print('\\n[query]' + query)\n",
        "  query_id = word_to_id[query]\n",
        "  query_vec = word_matrix[query_id]\n",
        "\n",
        "  vocab_size = word_matrix.shape[0]\n",
        "\n",
        "  # similarity\n",
        "  similarity = torch.zeros(vocab_size)\n",
        "  for i in range(vocab_size):\n",
        "    similarity[i] = cos_sim(word_matrix[i], query_vec)\n",
        "\n",
        "  # display\n",
        "  count = 0\n",
        "  for i in (-1 * similarity).argsort().cpu().numpy():\n",
        "    if id_to_word[i] == query:\n",
        "      continue\n",
        "\n",
        "    print('%s: %s' % (id_to_word[i], similarity[i]))\n",
        "\n",
        "    count += 1\n",
        "    if count >= top:\n",
        "      return\n"
      ],
      "metadata": {
        "id": "1pCDMfwy3Yt_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 類似度の表示\n",
        "query = [\"you\", \"year\", \"car\", \"toyota\"]\n",
        "for q in query:\n",
        "  most_sim(q, word_to_id, id_to_word, in_embeds_weights, top=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH-PcFOo6W8E",
        "outputId": "c8c82393-d4d7-4ba6-b6cf-c64ae13d1150"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[query]you\n",
            "your: tensor(0.6185)\n",
            "someone: tensor(0.6029)\n",
            "i: tensor(0.5925)\n",
            "yourself: tensor(0.5856)\n",
            "if: tensor(0.5657)\n",
            "\n",
            "[query]year\n",
            "earlier: tensor(0.6614)\n",
            "tons: tensor(0.4908)\n",
            "this: tensor(0.4774)\n",
            "fiscal: tensor(0.4753)\n",
            "guilders: tensor(0.4694)\n",
            "\n",
            "[query]car\n",
            "cars: tensor(0.6346)\n",
            "motor: tensor(0.5272)\n",
            "corsica: tensor(0.5172)\n",
            "auto: tensor(0.5078)\n",
            "lexus: tensor(0.4852)\n",
            "\n",
            "[query]toyota\n",
            "lexus: tensor(0.6925)\n",
            "infiniti: tensor(0.6675)\n",
            "luxury: tensor(0.6477)\n",
            "corsica: tensor(0.6421)\n",
            "motor: tensor(0.6327)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 類推問題\n",
        "# 以下のレポジトリを参考にしました\n",
        "# https://github.com/oreilly-japan/deep-learning-from-scratch-2/blob/master/common/util.py\n",
        "\n",
        "import torch\n",
        "from typing import Dict\n",
        "\n",
        "def analogy(a: str, b: str, c: str, word_to_id: Dict[str, int], id_to_word: Dict[int, str], word_matrix: torch.Tensor, top: int = 5, answer: str = None):\n",
        "  for word in (a, b, c):\n",
        "    if word not in word_to_id:\n",
        "      print(f'{word} is not found.')\n",
        "      return\n",
        "\n",
        "  print('\\n[analogy] ' + a + ':' + b + ' = ' + c + ':?')\n",
        "  a_vec, b_vec, c_vec = word_matrix[word_to_id[a]], word_matrix[word_to_id[b]], word_matrix[word_to_id[c]]\n",
        "  query_vec = b_vec - a_vec + c_vec\n",
        "  query_vec = normalize(query_vec)\n",
        "\n",
        "  # similarity\n",
        "  similarity = torch.mv(word_matrix, query_vec)\n",
        "\n",
        "  if answer is not None:\n",
        "    print('==>' + answer + ':' + str(torch.dot(word_matrix[word_to_id[answer]], query_vec)))\n",
        "\n",
        "  # display\n",
        "  count = 0\n",
        "  for i in (-1 * similarity).argsort().cpu().numpy():\n",
        "    if torch.isnan(similarity[i]):\n",
        "      continue\n",
        "\n",
        "    if id_to_word[i] in (a, b, c):\n",
        "      continue\n",
        "\n",
        "    print(' {0}: {1}'.format(id_to_word[i], similarity[i]))\n",
        "\n",
        "    count += 1\n",
        "    if count >= top:\n",
        "      return\n",
        "\n",
        "def normalize(x: torch.Tensor) -> torch.Tensor:\n",
        "  # テンソルの正規化\n",
        "  return x / torch.sqrt((x ** 2).sum())"
      ],
      "metadata": {
        "id": "gb3YDgZA87Ce"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 類推問題を解く(現状、良い結果は得られませんでした。。。)\n",
        "analogy('man', 'king', 'woman', word_to_id, id_to_word, in_embeds_weights, top=5)\n",
        "analogy('take', 'took', 'go', word_to_id, id_to_word, in_embeds_weights, top=5)\n",
        "analogy('car', 'cars', 'child', word_to_id, id_to_word, in_embeds_weights, top=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPasEZKbCGS8",
        "outputId": "a0e757ff-905a-4f42-e653-ceb6b1317eaa"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[analogy] man:king = woman:?\n",
            " disease: 1.5116997957229614\n",
            " user: 1.41786527633667\n",
            " epo: 1.4159584045410156\n",
            " rubicam: 1.406980276107788\n",
            " print: 1.3894294500350952\n",
            "\n",
            "[analogy] take:took = go:?\n",
            " ran: 1.382978916168213\n",
            " bought: 1.3222405910491943\n",
            " back: 1.2813529968261719\n",
            " kept: 1.225399136543274\n",
            " trap: 1.1942774057388306\n",
            "\n",
            "[analogy] car:cars = child:?\n",
            " rape: 2.307985305786133\n",
            " incest: 2.041339874267578\n",
            " serial: 1.956311821937561\n",
            " adults: 1.9404823780059814\n",
            " pregnant: 1.8595755100250244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "今回は計算リソースの都合、エポックを多めに設定できなかったため良い結果が得られなかったのではないかと考えられます。特に類推問題は、期待した結果からは大きく離れています。"
      ],
      "metadata": {
        "id": "0uYtO2zKKbKr"
      }
    }
  ]
}